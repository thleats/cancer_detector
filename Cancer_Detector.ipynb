{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F14hRWGFBrgm"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "import scipy\n",
        "from scipy import signal\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "print('hello world')\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "\n",
        "####################Paramters#####################\n",
        "###################################################\n",
        "\n",
        "epochs=20\n",
        "\n",
        "batch_size=15\n",
        "\n",
        "save_model=0\n",
        "\n",
        "save_images=1\n",
        "\n",
        "aws=0 #don't change this\n",
        "\n",
        "\n",
        "###################################################\n",
        "###################################################\n",
        "\n",
        "def count_parameters(model):\n",
        "    total_param = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            num_param = np.prod(param.size())\n",
        "            total_param += num_param\n",
        "    return total_param\n",
        "  \n",
        "\n",
        "assert torch.cuda.is_available() # You need to request a GPU from Runtime > Change Runtime Type\n",
        "  \n",
        "\n",
        "########################Convolution Network Class###############################\n",
        "parameters=[]\n",
        "class ConvNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNetwork,self).__init__()\n",
        "    c=3\n",
        "    out =2\n",
        "    channels=64\n",
        "    #####Create the first block\n",
        "    self.conv1=nn.Conv2d(c,channels,(3,3),padding=(1,1))\n",
        "    self.conv2=nn.Conv2d(channels,channels,(3,3),padding=(1,1))\n",
        "    \n",
        "    \n",
        "    #####Copy to the last block   \n",
        "    \n",
        "    #####Create the second block\n",
        "    self.conv4=nn.Conv2d(channels,channels*2,(3,3),padding=(1,1))\n",
        "    self.conv5=nn.Conv2d(channels*2,channels*2,(3,3),padding=(1,1))\n",
        "    \n",
        "    \n",
        "    #####Copy to the 2nd to last block\n",
        "    \n",
        "    #####Create the third block\n",
        "    self.conv7=nn.Conv2d(channels*2,channels*4,(3,3),padding=(1,1))\n",
        "    self.conv8=nn.Conv2d(channels*4,channels*4,(3,3),padding=(1,1))\n",
        "    \n",
        "    \n",
        "    #####Copy to the 3rd to last block\n",
        "    \n",
        "    #####Create the fourth block\n",
        "    self.conv10=nn.Conv2d(channels*4,channels*8,(3,3),padding=(1,1))\n",
        "    self.conv11=nn.Conv2d(channels*8,channels*8,(3,3),padding=(1,1))\n",
        "    \n",
        "    \n",
        "    #####Copy to the 4th to last block\n",
        "    \n",
        "    #####Create the fifth block\n",
        "    self.conv13=nn.Conv2d(channels*8,channels*16,(3,3),padding=(1,1))\n",
        "    self.conv14=nn.Conv2d(channels*16,channels*16,(3,3),padding=(1,1))\n",
        "   \n",
        "    \n",
        "    #####Upsample to sixth block\n",
        "    self.conv15=nn.ConvTranspose2d(channels*16,channels*8,2,stride=2,padding=0)\n",
        "    self.conv16=nn.Conv2d(channels*16,channels*8,(3,3),padding=(1,1))\n",
        "    self.conv17=nn.Conv2d(channels*8,channels*8,(3,3),padding=(1,1))\n",
        "\n",
        "    \n",
        "    #####Upsabmle to seventh block\n",
        "    self.conv18=nn.ConvTranspose2d(channels*8,channels*4,(2,2),padding=0,stride=2)\n",
        "    self.conv19=nn.Conv2d(channels*8,channels*4,(3,3),padding=(1,1))\n",
        "    self.conv20=nn.Conv2d(channels*4,channels*4,(3,3),padding=(1,1))\n",
        "   \n",
        "    \n",
        "    #####Upsample to eigth block\n",
        "    self.conv21=nn.ConvTranspose2d(channels*4,channels*2,(2,2),padding=0,stride=2)\n",
        "    self.conv22=nn.Conv2d(channels*4,channels*2,(3,3),padding=(1,1))\n",
        "    self.conv23=nn.Conv2d(channels*2,channels*2,(3,3),padding=(1,1))\n",
        "\n",
        "    \n",
        "    #####Upsample to ningth block\n",
        "    self.conv24=nn.ConvTranspose2d(channels*2,channels,(2,2),padding=0,stride=2)\n",
        "    self.conv25=nn.Conv2d(channels*2,channels,(3,3),padding=(1,1))\n",
        "    self.conv26=nn.Conv2d(channels,channels,(3,3),padding=(1,1))\n",
        "    self.conv27=nn.Conv2d(channels,out,(1,1),padding=(0,0))\n",
        "    \n",
        "  \n",
        "    self.activation = nn.ReLU()\n",
        "  \n",
        "  def forward(self,x):\n",
        "    n,c,h,w = x.size()\n",
        "    memory=[]\n",
        "    \n",
        "    o1=self.activation(self.conv1(x))\n",
        "    #print(o1.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o2=self.activation(self.conv2(o1))#o2 to o24\n",
        "    #print(o2.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    size_tensor=o2.size()\n",
        "    variable=size_tensor[2]/2\n",
        "    \n",
        "    ##\n",
        "    #torch.cat((o1,o24),1)\n",
        "    #pdb.set_trace()\n",
        "    m=nn.AdaptiveMaxPool2d(int(variable))\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o3=m(o2)\n",
        "    #print(o3.size())\n",
        "    o4=self.activation(self.conv4(o3))\n",
        "    #print(o4.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o5=self.activation(self.conv5(o4))#o5 to o21\n",
        "    #print(o5.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    \n",
        "    size_tensor=o5.size()\n",
        "    variable=size_tensor[2]/2\n",
        "    ##\n",
        "    m=nn.AdaptiveMaxPool2d(int(variable))\n",
        "    \n",
        "    o6=m(o5)\n",
        "    #print(o6.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o7=self.activation(self.conv7(o6))\n",
        "    #print(o7.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o8=self.activation(self.conv8(o7))#o8 to o18\n",
        "    #print(o8.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    \n",
        "    size_tensor=o8.size()\n",
        "    variable=size_tensor[2]/2\n",
        "    ##\n",
        "    m=nn.AdaptiveMaxPool2d(int(variable))\n",
        "    o9=m(o8)\n",
        "    #print(o9.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o10=self.activation(self.conv10(o9))\n",
        "    #print(o10.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o11=self.activation(self.conv11(o10))#o11 to o15\n",
        "    #print(o11.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    \n",
        "    size_tensor=o11.size()\n",
        "    variable=size_tensor[2]/2\n",
        "    ##\n",
        "    m=nn.AdaptiveMaxPool2d(int(variable))\n",
        "    o12=m(o11)\n",
        "    #print(o12.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)    \n",
        "    o13=self.activation(self.conv13(o12))\n",
        "    #print(o13.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o14=self.activation(self.conv14(o13))\n",
        "    #print(o14.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    ##\n",
        "    \n",
        "    #m=nn.Upsample(28)\n",
        "    \n",
        "    o15=self.conv15(o14)\n",
        "    #print(o15.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o15=torch.cat((o11,o15),1)\n",
        "    #print(o15.size())\n",
        "    #\n",
        "    o16=self.activation(self.conv16(o15))\n",
        "    #print(o16.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o17=self.activation(self.conv17(o16))\n",
        "    #print(o17.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    ##\n",
        "    #m=nn.Upsample(28)\n",
        "    o18=self.conv18(o17)\n",
        "    #print(o18.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o18=torch.cat((o8,o18),1)\n",
        "    #print(o18.size())\n",
        "    o19=self.activation(self.conv19(o18))\n",
        "    #print(o19.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o20=self.activation(self.conv20(o19))\n",
        "    #print(o20.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    ##\n",
        "    #m=nn.Upsample(28)\n",
        "    #pdb.set_trace()\n",
        "    o21=self.conv21(o20)\n",
        "    #print(o21.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o21=torch.cat((o5,o21),1)\n",
        "    #print(o21.size())\n",
        "    o22=self.activation(self.conv22(o21))\n",
        "    #print(o22.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o23=self.activation(self.conv23(o22))\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    #print(o23.size())\n",
        "    ##\n",
        "    \n",
        "    #m=nn.Upsample(28)\n",
        "    o24=self.conv24(o23)\n",
        "    #print(o24.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o24=torch.cat((o2,o24),1)\n",
        "    #print(o24.size())\n",
        "    o25=self.activation(self.conv25(o24))\n",
        "    #print(o25.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    o26=self.activation(self.conv26(o25))\n",
        "    #print(o26.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    \n",
        "    o27=self.conv27(o26)\n",
        "    #print(o27.size())\n",
        "    memory.append(torch.cuda.memory_allocated(0)/1e9)\n",
        "    #pdb.set_trace()\n",
        "    #fig, ax = plt.subplots()\n",
        "    #plt.plot(memory)\n",
        "    #ax=plt.gca()\n",
        "    #loss_v=ax.plot(memory)\n",
        "    #loss_t=ax.plot(iterations,losses,label='Training Loss')\n",
        "    #acc=ax.plot(iterations,acc_vec,label='Accuracy Validation')\n",
        "    #acc_t=ax.plot(iterations,acc_vec_t,label='Accuracy Training')\n",
        "\n",
        "\n",
        "\n",
        "    #ax.legend()\n",
        "\n",
        "\n",
        "    #ax.set(xlabel='U-net layer #', ylabel='GPU Memory Usage - GB',\n",
        "           #title='U-net Layers vs GPU Memory usage')\n",
        "    #ax.grid()\n",
        "    \n",
        "    #plt.show()\n",
        "    return o27.squeeze(2).squeeze(2)\n",
        "    \n",
        "\n",
        "        \n",
        "    \n",
        "class CancerDataset(Dataset):\n",
        "  def __init__(self, root, download=True, size=256, train=True):\n",
        "    if download and not os.path.exists(os.path.join(root, 'cancer_data')):\n",
        "      datasets.utils.download_url('https://nolans-cs-bucket.s3-us-west-1.amazonaws.com/cancer_data.tar.gz', root, 'cancer_data.tar.gz', None)\n",
        "      self.extract_gzip(os.path.join(root, 'cancer_data.tar.gz'))\n",
        "      self.extract_tar(os.path.join(root, 'cancer_data.tar'))\n",
        "    \n",
        "    postfix = 'train' if train else 'test'\n",
        "    root = os.path.join(root, 'cancer_data', 'cancer_data')\n",
        "    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, 'inputs_' + postfix) ,transform = transforms.Compose([transforms.Resize(size),transforms.ToTensor()]))\n",
        "    self.label_folder = torchvision.datasets.ImageFolder(os.path.join(root, 'outputs_' + postfix) ,transform = transforms.Compose([transforms.Resize(size),transforms.ToTensor()]))\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_gzip(gzip_path, remove_finished=False):\n",
        "    print('Extracting {}'.format(gzip_path))\n",
        "    with open(gzip_path.replace('.gz', ''), 'wb') as out_f, gzip.GzipFile(gzip_path) as zip_f:\n",
        "      out_f.write(zip_f.read())\n",
        "    if remove_finished:\n",
        "      os.unlink(gzip_path)\n",
        "  \n",
        "  @staticmethod\n",
        "  def extract_tar(tar_path):\n",
        "    print('Untarring {}'.format(tar_path))\n",
        "    z = tarfile.TarFile(tar_path)\n",
        "    z.extractall(tar_path.replace('.tar', ''))\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img = self.dataset_folder[index]\n",
        "    label = self.label_folder[index]\n",
        "    return img[0],label[0][0]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)\n",
        "    #return 30\n",
        "    \n",
        "def compute_accuracy(y_hat,y_truth):\n",
        "  test=torch.argmax(y_hat,dim=1)\n",
        "  y_truth=y_truth.long()\n",
        "  \n",
        "  test2=test==y_truth\n",
        "  chn=test.size()\n",
        "  pix=test.size(2)\n",
        "  print(\"pix is:\"+ str(pix))\n",
        "  out=torch.sum(test2).item()/(pix*pix*chn[0])\n",
        "  \n",
        "  return out\n",
        "\n",
        "\n",
        "############### #LOADING AND TRAINING  ################################\n",
        "########################################################################\n",
        "########################################################################\n",
        "########################################################################\n",
        "    \n",
        "    \n",
        "\n",
        "##load data\n",
        "train_dataset=CancerDataset('/tmp/cancer_train',train=True)\n",
        "val_dataset=CancerDataset('/tmp/cancer_test',train=False)\n",
        "\n",
        "#create model\n",
        "model = ConvNetwork()\n",
        "#send model to GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
        "  model = nn.DataParallel(model)\n",
        "  aws=1\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "#model.cuda()\n",
        "\n",
        "#define the objective function\n",
        "objective = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "#define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
        "\n",
        "\n",
        "\n",
        "losses=[]\n",
        "losses_valid=[]\n",
        "loss_mean=[]\n",
        "acc_vec=[]\n",
        "acc_epoch=[]\n",
        "accuracy_v=[]\n",
        "accuracy_t=[]\n",
        "acc_vec_t=[]\n",
        "acc_vec_loop=[]\n",
        "acc_v_loop=[]\n",
        "memory_t=[]\n",
        "memory_v=[]\n",
        "memory_t_temp=[]\n",
        "memory_v_temp=[]\n",
        "\n",
        "\n",
        "\n",
        "if aws==1:\n",
        "  workers=64\n",
        "else:\n",
        "  workers=2\n",
        "  \n",
        "  \n",
        " #define the batch loader for training \n",
        "train_loader = DataLoader(train_dataset,\n",
        "                           batch_size=batch_size,\n",
        "                           pin_memory=True,num_workers=workers)  \n",
        "  \n",
        "  #define teh batch loader for validation\n",
        "valid_load = DataLoader(val_dataset,\n",
        "                        batch_size=round(len(val_dataset)/len(train_loader)),\n",
        "                        pin_memory=True,num_workers=workers)\n",
        "\n",
        "#break\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "############################ START OF EPOCH LOOP ###############################\n",
        "\n",
        "epoch_counter=1\n",
        "for epoch in range(epochs):\n",
        "  loop = tqdm(total=len(train_loader), position = 0)\n",
        "  loop2 = tqdm(total=len(valid_load), position = 0)\n",
        "  \n",
        "  #########################START OF BATCH LOOP #############################\n",
        "  \n",
        "  ####################TRAINING\n",
        "  for batch in train_loader:\n",
        "    x=batch[0]\n",
        "    y_truth=batch[1]\n",
        "    x=x.cuda()\n",
        "    y_truth=y_truth.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    y_hat=model(x)\n",
        "    \n",
        "    acc = np.mean(compute_accuracy(y_hat, y_truth))\n",
        "    dims = y_truth.size()\n",
        "    y_truth = y_truth.long()\n",
        "    loss = objective(y_hat, y_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss)\n",
        "    acc_vec_loop.append(acc)\n",
        "    memory_t_temp=torch.cuda.memory_allocated(0)/1e9\n",
        "    loop.update(1)\n",
        "    \n",
        "    \n",
        "  memory_t.append(memory_t_temp)\n",
        "  gc.collect()\n",
        "  acc_vec.append(np.mean(acc_vec_loop))\n",
        "  loop.set_description('training loss:{:.4f}'.format(loss.item()))\n",
        "\n",
        "  #####################VALIDATION\n",
        "  for x_valid,y_truth_valid in valid_load:\n",
        "    \n",
        "    x_valid,y_truth_valid = x_valid.cuda(async=True),y_truth_valid.cuda(async=True)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      y_nohat=model(x_valid)\n",
        "      \n",
        "      acc_v = np.mean(compute_accuracy(y_nohat,y_truth_valid))\n",
        "      y_truth_valid=y_truth_valid.long()\n",
        "      temp=objective(y_nohat,y_truth_valid)\n",
        "      \n",
        "    #accuracy_v.append(acc_v)\n",
        "    temp_cpu=temp.cpu()\n",
        "    #loss_mean.append(np.mean(temp))\n",
        "    \n",
        "    losses_valid.append(temp_cpu.item())\n",
        "    acc_v_loop.append(np.mean(acc_v))\n",
        "    memory_v_temp=(torch.cuda.memory_allocated(0)/1e9)\n",
        "    gc.collect()\n",
        "    loop2.update(1)\n",
        "  memory_v.append(memory_v_temp)\n",
        "  accuracy_v.append(np.mean(acc_v_loop))\n",
        "  loop2.set_description('validation loss:{:.4f}'.format(losses_valid[-1]))\n",
        "  \n",
        "  \n",
        "  ##################### PART 3 OF LAB - IMAGE 72\n",
        "  if save_images==1:\n",
        "  \n",
        "    for things in valid_load:\n",
        "      break\n",
        "    original=things[0][0]\n",
        "    original=original.unsqueeze(0).cuda()\n",
        "\n",
        "    truth=things[1][0]\n",
        "    truth_cuda=truth.cuda()\n",
        "\n",
        "    yhat_eval=model(original)\n",
        "    yhat_eval_sm=torch.nn.functional.softmax(yhat_eval, dim=1)\n",
        "    yhat_mask=torch.argmax(yhat_eval_sm,dim=1)\n",
        "    yhat_mask=yhat_mask.squeeze(0).cuda()\n",
        "\n",
        "    accuracy_image = compute_accuracy(yhat_eval,truth_cuda)\n",
        "    original.squeeze_(0)\n",
        "    original_cpu=original.cpu()\n",
        "    r=original_cpu[0]\n",
        "    g=original_cpu[1]\n",
        "    b=original_cpu[2]\n",
        "\n",
        "    image=np.zeros((1024,1024,3))\n",
        "    image[:,:,0]=r\n",
        "    image[:,:,1]=g\n",
        "    image[:,:,2]=b\n",
        "    \n",
        "    fig=plt.figure(figsize=(15,10))\n",
        "    fig.suptitle('U-Net Data Plots - 1024x1024 pixels',fontsize=25)\n",
        "    ax1=fig.add_subplot(231)\n",
        "    \n",
        "    plt.imshow(yhat_mask.cpu())\n",
        "    location=yhat_mask.size(1)/2\n",
        "    acc_string=str(accuracy_image)\n",
        "    plt.text(location,location*1.5,'accuracy = ' + acc_string[0:5],verticalalignment='center',horizontalalignment='center',color='w')\n",
        "    plt.text(location,location*1.75,'epoch ' + str(epoch_counter),verticalalignment='center',horizontalalignment='center',color='w')\n",
        "    \n",
        "\n",
        "    ax2=fig.add_subplot(232)\n",
        "    \n",
        "    plt.subplot(232)\n",
        "    plt.text(location,location*1.5,'truth',verticalalignment='center',horizontalalignment='center',color='w')\n",
        "    truth_cpu=truth.cpu()\n",
        "    plt.imshow(truth_cpu)\n",
        "    \n",
        "   \n",
        "    ax3=fig.add_subplot(233)\n",
        "    \n",
        "    plt.text(location,location*1.5,'original',verticalalignment='center',horizontalalignment='center')\n",
        "    plt.imshow(image)\n",
        "    \n",
        "    \n",
        "    ax4=fig.add_subplot(234)\n",
        "    \n",
        "    iterations=range(0,len(losses),1) \n",
        "    valid_iterations=range(0,len(losses_valid),1)\n",
        "    plt.plot(valid_iterations,losses_valid,label='Validation Loss')\n",
        "    plt.plot(iterations,losses,label='Training Loss')\n",
        "    ax4.legend(loc=\"upper right\")\n",
        "    ax4.title.set_text('Loss vs Iterations')\n",
        "    ax4.set_xlabel('iterations')\n",
        "    ax4.set_ylabel('loss')\n",
        "    \n",
        "    \n",
        "    ax5=fig.add_subplot(235)\n",
        "    \n",
        "    iterations_t=range(0,len(acc_vec),1)\n",
        "    iterations_v=range(0,len(accuracy_v),1)\n",
        "    plt.plot(iterations_t,acc_vec,label='Validation Accuracy')\n",
        "    plt.plot(iterations_v,accuracy_v,label='Training Accuracy')\n",
        "    ax5.legend(loc=\"lower right\")\n",
        "    ax5.title.set_text('Accuracy vs Iterations')\n",
        "    ax5.set_xlabel('iterations')\n",
        "    ax5.set_ylabel('accuracy')\n",
        "    \n",
        "    \n",
        "    #ax6=fig.add_subplot(236)\n",
        "    #epochs_memory=range(0,len(memory_t),1)\n",
        "    #plt.plot(epochs_memory,memory_t,label='training memory')\n",
        "    #plt.plot(epochs_memory,memory_v,label='validation memory')\n",
        "    #ax6.legend(loc=\"lower right\")\n",
        "    #ax6.set_xlabel('epochs')\n",
        "    #ax6.title.set_text('GPU memory usage vs epochs')\n",
        "    #ax6.set_ylabel('GPU memory usage-GB')\n",
        "    \n",
        "    plt.subplots_adjust(wspace=0.25)\n",
        "    if aws==0:\n",
        "      from google.colab import drive\n",
        "      drive.mount('/content/drive')\n",
        "      with open('/content/drive/My Drive/image_' + str(epoch_counter) + '.png', 'w') as f:\n",
        "        out=plt.savefig('/content/drive/My Drive/image_' + str(epoch_counter) + '.png')\n",
        "    if aws==1:\n",
        "      with open('/home/ubuntu/image_' + str(epoch_counter) + '.png', 'w') as f:\n",
        "        out=plt.savefig('/home/ubuntu/image_' + str(epoch_counter) + '.png')\n",
        "\n",
        "    \n",
        "    print(\"images saved\")\n",
        "  \n",
        "  \n",
        "  epoch_counter=epoch_counter+1   \n",
        "  loop.close()\n",
        " #########################END OF EPOCH LOOP ############################# \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################## POSTPROCESSING ################################\n",
        "########################################################################\n",
        "########################################################################\n",
        "########################################################################\n",
        "\n",
        "#################SAVE MODEL\n",
        "if save_model==1:\n",
        "  with open('/home/ubuntu/foo.txt', 'w') as f:\n",
        "    out=torch.save(model.state_dict(),'/home/ubuntu/foo.txt')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Cancer Detector v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
